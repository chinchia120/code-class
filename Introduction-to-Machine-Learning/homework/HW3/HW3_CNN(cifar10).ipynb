{"cells":[{"cell_type":"markdown","metadata":{"id":"H3OiPyUSYyX0"},"source":["# **Assignment 3. Image Classification Using Convolution Neural Network**\n","\n","* 使用Convolutional Neural Network (e.g., VGG-like CNN)\n","* 模型測試(Testing)時使用所有測試資料(10000筆資料)\n","* 在相同的NN模型參數(epoch, batch size, optimizer, activation function)與約略相同的模型大小之下比較CNN與FC models的分類正確度"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1669213875233,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"NnBdVfe7Eb3G"},"outputs":[],"source":["# Import\n","import os\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","from tensorflow.keras import utils\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, BatchNormalization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4896,"status":"ok","timestamp":1669213881991,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"_2078qIOhCTj","outputId":"fbdb975c-13bd-4b44-de5e-b207365cf4d8"},"outputs":[],"source":["# Set Direction\n","drive.mount('/content/gdrive')\n","os.chdir('/content/gdrive/My Drive/data/tmp/Introduction-to-Machine-Learning/homework/HW3')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":794},"executionInfo":{"elapsed":5308,"status":"ok","timestamp":1669213887295,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"pnf303mdAv5-","outputId":"f3253413-af46-4560-a9b8-c363bebe9a3c"},"outputs":[],"source":["# Load Data and Normalization\n","(x_train_image, y_train_label), (x_test_image, y_test_label) = cifar10.load_data()\n","class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n","\n","def plot_multiimages(images, labels, prediction, idx, num=25):\n","    plt.gcf().set_size_inches(12, 14)\n","    if num > 25: num = 25\n","    for i in range(0, num):\n","        ax=plt.subplot(5,5, 1+i)\n","        ax.imshow(images[idx])\n","        title = \" l= \" + class_names[int(labels[idx])]\n","        if len(prediction) > 0:\n","            title = \"l = {}, p = {}\".format(class_names[int(labels[idx])], class_names[prediction[idx]])\n","        else:\n","            title = \"l = {}\".format(class_names[int(labels[idx])])\n","        ax.set_title(title, fontsize=10)\n","        ax.set_xticks([]); ax.set_yticks([])\n","        idx+=1\n","    plt.show()\n","plot_multiimages(x_train_image, y_train_label, [], 100, 25)\n","\n","x_train_CNN = x_train_image.reshape(len(x_train_image), 32, 32, 3).astype('float32')\n","x_test_CNN = x_test_image.reshape(len(x_test_image), 32, 32, 3).astype('float32')\n","x_train_norm_CNN = x_train_CNN/255  \n","x_test_norm_CNN = x_test_CNN/255\n","y_TrainOneHot_CNN = utils.to_categorical(y_train_label)\n","y_TestOneHot_CNN = utils.to_categorical(y_test_label)\n","\n","x_train_FC = x_train_image.reshape(len(x_train_image), 32*32*3).astype('float32')\n","x_test_FC = x_test_image.reshape(len(x_test_image), 32*32*3).astype('float32')\n","x_train_norm_FC = x_train_FC/255  \n","x_test_norm_FC = x_test_FC/255\n","y_TrainOneHot_FC = utils.to_categorical(y_train_label)\n","y_TestOneHot_FC = utils.to_categorical(y_test_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1669213887296,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"BNSFsYDhXBec"},"outputs":[],"source":["# Show Train History\n","def show_train_history(train_history, train, validation, filename):  \n","    plt.plot(train_history.history[train])\n","    plt.plot(train_history.history[validation])\n","    plt.title('Train History')  \n","    plt.xlabel('Epoch') \n","    plt.ylabel(train)  \n","    plt.legend(['train', 'validation'], loc='upper left')  \n","    plt.savefig(filename)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1669213887296,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"qwo1nnypAz8V","outputId":"4b47111c-8b0e-42db-ef69-8a46a9432dc9"},"outputs":[],"source":["# Build a Convolution Neural Network\n","input_CNN = Input(shape=(32, 32, 3))\n","\n","# 1-1\n","conv1_1 = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(input_CNN)\n","conv1_1 = BatchNormalization()(conv1_1)\n","# 1-2\n","conv1_2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(conv1_1)\n","conv1_2 = BatchNormalization()(conv1_2)\n","# Pool1\n","maxPool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n","\n","# 2-1\n","conv2_1 = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(maxPool1)\n","conv2_1 = BatchNormalization()(conv2_1)\n","# 2-2\n","conv2_2 = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(conv2_1)\n","conv2_2 = BatchNormalization()(conv2_2)\n","# Pool2\n","maxPool2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)\n","\n","# 3-1\n","conv3_1 = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(maxPool2)\n","conv3_1 = BatchNormalization()(conv3_1)\n","# 3-2\n","conv3_2 = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(conv3_1)\n","conv3_2 = BatchNormalization()(conv3_2)\n","# 3-3\n","conv3_3 = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(conv3_2)\n","conv3_3 = BatchNormalization()(conv3_3)\n","# 3-4\n","conv3_4 = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(conv3_3)\n","conv3_4 = BatchNormalization()(conv3_4)\n","# Pool3\n","maxPool3 = MaxPooling2D(pool_size=(2, 2))(conv3_4)\n","\n","# 4-1\n","conv4_1 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(maxPool3)\n","conv4_1 = BatchNormalization()(conv4_1)\n","# 4-2\n","conv4_2 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv4_1)\n","conv4_2 = BatchNormalization()(conv4_2)\n","# 4-3\n","conv4_3 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv4_2)\n","conv4_3 = BatchNormalization()(conv4_3)\n","# 4-3\n","conv4_4 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv4_3)\n","conv4_4 = BatchNormalization()(conv4_4)\n","# Pool4\n","maxPool4 = MaxPooling2D(pool_size=(2, 2))(conv4_4)\n","\n","# 5-1\n","conv5_1 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(maxPool4)\n","conv5_1 = BatchNormalization()(conv5_1)\n","# 5-2\n","conv5_2 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv5_1)\n","conv5_2 = BatchNormalization()(conv5_2)\n","# 5-3\n","conv5_3 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv5_2)\n","conv5_3 = BatchNormalization()(conv5_3)\n","# 5-4\n","conv5_4 = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(conv5_3)\n","conv5_4 = BatchNormalization()(conv5_4)\n","# Pool5\n","maxPool5 = MaxPooling2D(pool_size=(2, 2))(conv5_4)\n","\n","# Flatten\n","flat1 = Flatten()(maxPool5)\n","\n","# Fully Connection Layer\n","dense1 = Dropout(0.35)(Dense(units=1024, activation='relu')(flat1))\n","dense2 = Dropout(0.35)(Dense(units=512, activation='relu')(dense1))\n","output_CNN = Dense(units=10, activation='softmax')(dense2)\n","\n","# Summary\n","model_CNN = Model(input_CNN, output_CNN)\n","model_CNN.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":702242,"status":"ok","timestamp":1669214589531,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"rvoAo9vsMrVL","outputId":"b1406f1b-4e1d-4166-a8d2-896629ff2939"},"outputs":[],"source":["# Train Convolution Neural Network Model\n","model_CNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","train_history_CNN = model_CNN.fit(x=x_train_norm_CNN, y=y_TrainOneHot_CNN, validation_split=0.2, epochs=20, batch_size=64, verbose=1)\n","\n","show_train_history(train_history_CNN, 'accuracy', 'val_accuracy', './picture/CNN_train_history_accuracy.png')\n","show_train_history(train_history_CNN, 'loss', 'val_loss', './picture/CNN_train_history_loss.png')\n","\n","scores = model_CNN.evaluate(x_test_norm_CNN[0:10000], y_TestOneHot_CNN[0:10000])\n","print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))\n","\n","# Save CNN Model\n","torch.save(model_CNN, './model_CNN.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1669214589532,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"zRQOuXlo3j2D","outputId":"0b7983ce-0da1-4a83-dab4-67e69991eb08"},"outputs":[],"source":["# Build a Fully Connection Layer\n","input_FC = Input(shape=(32*32*3))\n","\n","dense1 = Dropout(0.35)(Dense(units=2048, activation='relu')(input_FC))\n","dense2 = Dropout(0.35)(Dense(units=2048, activation='relu')(dense1))\n","dense3 = Dropout(0.35)(Dense(units=2048, activation='relu')(dense2))\n","dense4 = Dropout(0.35)(Dense(units=1024, activation='relu')(dense3))\n","dense5 = Dropout(0.35)(Dense(units=1024, activation='relu')(dense4))\n","dense6 = Dropout(0.35)(Dense(units=1024, activation='relu')(dense5))\n","dense7 = Dropout(0.35)(Dense(units=1024, activation='relu')(dense6))\n","dense8 = Dropout(0.35)(Dense(units=512, activation='relu')(dense7))\n","dense9 = Dropout(0.35)(Dense(units=512, activation='relu')(dense8))\n","dense10 = Dropout(0.35)(Dense(units=512, activation='relu')(dense9))\n","dense11 = Dropout(0.35)(Dense(units=512, activation='relu')(dense10))\n","dense12 = Dropout(0.35)(Dense(units=256, activation='relu')(dense11))\n","dense13 = Dropout(0.35)(Dense(units=256, activation='relu')(dense12))\n","dense14 = Dropout(0.35)(Dense(units=256, activation='relu')(dense13))\n","dense15 = Dropout(0.35)(Dense(units=256, activation='relu')(dense14))\n","\n","output_FC = Dense(units=10, activation='softmax')(dense15)\n","\n","model_FC = Model(input_FC, output_FC)\n","model_FC.summary() "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":151684,"status":"ok","timestamp":1669214741208,"user":{"displayName":"F64091091許晋嘉","userId":"06185607768820272367"},"user_tz":-480},"id":"ftzvAWwYXBef","outputId":"c8b6e6b6-2691-4a08-f8ee-a14c19cdc000"},"outputs":[],"source":["# Train Fully Connection Layer Model\n","model_FC.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","train_history_FC = model_FC.fit(x=x_train_norm_FC, y=y_TrainOneHot_FC, validation_split=0.2, epochs=20, batch_size=64, verbose=1)\n","\n","show_train_history(train_history_FC, 'accuracy', 'val_accuracy', './picture/FC_train_history_accuracy.png')\n","show_train_history(train_history_FC, 'loss', 'val_loss', './picture/FC_train_history_loss.png')\n","\n","scores = model_FC.evaluate(x_test_norm_FC[0:10000], y_TestOneHot_FC[0:10000])\n","print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))\n","\n","# Save ANN Model\n","torch.save(model_FC, './model_FC.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"}}},"nbformat":4,"nbformat_minor":0}
